#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ ‡ç­¾æ¸…æ´—ï¼šæ”¯æŒé˜ˆå€¼è°ƒæ•´ + å¤šç®—æ³•é›†æˆ
å¯ä½¿ç”¨å¤šæƒé‡
- CleanLab
- K-Means èšç±»å¼‚å¸¸æ£€æµ‹
- Isolation Forest å…¨å±€å¼‚å¸¸æ£€æµ‹
- é›†æˆæŠ•ç¥¨å†³ç­–
"""

from __future__ import annotations

import shutil
import time
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import numpy as np
import pandas as pd
from cleanlab.classification import CleanLearning
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from tqdm import tqdm
from ultralytics import YOLO
import yaml

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é…ç½®å‚æ•° (å«é»˜è®¤å€¼è¯´æ˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_DIR: Path = Path(__file__).resolve().parent
PROJECT_ROOT: Path = SCRIPT_DIR.parent.parent.parent

CONFIG: dict = {
    "DATA_DIR": PROJECT_ROOT / "datasets/cls/raw/affectnet",    # æ•°æ®é›†æ ¹ç›®å½•
    "KFOLD": 5,  # KæŠ˜äº¤å‰éªŒè¯æŠ˜æ•°
    "BATCH_SIZE": 32,   # æ¨ç†æ‰¹å¤§å°
    "CONF_THRESH": 0.001,   # ç½®ä¿¡åº¦é˜ˆå€¼
    "OUTPUT_DIR": SCRIPT_DIR.parent / "caches",    # è¾“å‡ºç›®å½•
    "SUSPECTS_DIR": SCRIPT_DIR.parent / "caches/suspects", # å¯ç–‘å›¾ç‰‡è¾“å‡ºç›®å½•
    "CLEAN_DIR": SCRIPT_DIR.parent / "caches/clean",   # å¹²å‡€å›¾ç‰‡è¾“å‡ºç›®å½•
    "SAVE_IMGS": True,  # æ˜¯å¦ä¿å­˜å›¾ç‰‡
    "CACHE_DIR": SCRIPT_DIR.parent / "caches/cache",  # ç¼“å­˜ç›®å½•
    "TRAIN_PARAMS": {  # é»˜è®¤è¶…å‚ï¼Œå¯è‡ªè¡Œè°ƒ
        "epochs": 150,
        "imgsz": 224,
        "batch": 32,
        "patience": 20,
        "device": "0"  # å¤š GPU å†™ "0,1,2"
    },

    # K-Meanså‚æ•°
    "KMEANS_CONFIG": {
        "n_clusters_ratio": 0.1,  # æ¨è: 0.05-0.2
        "min_clusters": 2,  # æ¨è: 2-5
        "max_clusters": 20,  # æ¨è: 10-50
        "contamination": 0.1,  # æ¨è: 0.05-0.2
        "random_state": 42  # æ¨è: å›ºå®šå€¼ç¡®ä¿å¯é‡å¤
    },

    # Isolation Forestå‚æ•°
    "ISOLATION_CONFIG": {
        "contamination": 0.1,  # é»˜è®¤: "auto", æ¨è: 0.05-0.2
        "n_estimators": 100,  # é»˜è®¤: 100
        "random_state": 42,  # é»˜è®¤: None
        "n_jobs": -1  # é»˜è®¤: None
    },

    # é›†æˆæŠ•ç¥¨å‚æ•°
    "ENSEMBLE_CONFIG": {
        "voting_threshold": 2,  # æ¨è: 1(å®½æ¾) 2(å¹³è¡¡) 3(ä¸¥æ ¼)
        "quality_score_weight": {  # æƒé‡å»ºè®®æ ¹æ®ä½ çš„æ•°æ®è°ƒæ•´
            "cleanlab": 0.5,  # CleanLabé€šå¸¸æœ€å¯é 
            "kmeans": 0.3,  # K-Meansé€‚åˆç±»å†…å¼‚å¸¸
            "isolation": 0.2  # Isolation Forestæ‰¾å…¨å±€å¼‚å¸¸
        }
    }

}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”„ æ•°æ®åŠ è½½å’Œæ¨ç†å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_dataset(data_dir: Path) -> Tuple[List[Path], List[int], Dict[int, str]]:
    """è¯»å–æ–‡ä»¶å¤¹å¼æ•°æ®é›†ï¼Œæ”¯æŒé€’å½’æœç´¢å›¾ç‰‡æ–‡ä»¶ã€‚"""
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–æ•°æ®é›†: {data_dir}")
    if not data_dir.exists():
        raise ValueError(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")

    class_dirs = sorted([p for p in data_dir.iterdir() if p.is_dir()])
    if not class_dirs:
        raise ValueError(f"âŒ æœªåœ¨ {data_dir} ä¸‹æ‰¾åˆ°ä»»ä½•ç±»åˆ«å­æ–‡ä»¶å¤¹")

    label_map = {idx: p.name for idx, p in enumerate(class_dirs)}
    img_paths, labels = [], []

    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼ˆWindowsç³»ç»Ÿä½¿ç”¨ä¸åŒºåˆ†å¤§å°å†™çš„æ–¹å¼ï¼‰
    img_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp']

    # æ·»åŠ è¿›åº¦æ¡æ˜¾ç¤ºç±»åˆ«å¤„ç†è¿‡ç¨‹
    for idx, cls_dir in enumerate(tqdm(class_dirs, desc="ğŸ“ æ‰«æç±»åˆ«ç›®å½•")):
        print(f"   ğŸ“ å¤„ç†ç±»åˆ«: {cls_dir.name}")

        # ä½¿ç”¨é›†åˆé¿å…é‡å¤æ–‡ä»¶
        paths_set = set()
        for ext in img_extensions:
            # åªæœç´¢å°å†™æ‰©å±•åï¼Œåœ¨Windowsä¸Šä¼šåŒæ—¶åŒ¹é…å¤§å°å†™
            for path in cls_dir.rglob(f"*{ext}"):
                paths_set.add(path)

        paths = list(paths_set)

        if paths:
            img_paths.extend(paths)
            labels.extend([idx] * len(paths))
            print(f"      æ‰¾åˆ° {len(paths)} å¼ å›¾ç‰‡")
        else:
            print(f"      âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")

    print(f"âœ… æ•°æ®åŠ è½½å®Œæˆï¼Œå…± {len(img_paths)} å¼ å›¾ç‰‡ï¼Œ{len(label_map)} ä¸ªç±»åˆ«")
    print(f"ğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
    for idx, name in label_map.items():
        count = sum(1 for label in labels if label == idx)
        print(f"   {idx}: {name} - {count} å¼ ")

    return img_paths, labels, label_map


def _batch_predict(
        models: List[YOLO],
        paths: List[Path],
        batch_size: int,
        conf: float,
        fold_id: int = 0,
) -> np.ndarray:
    """é›†æˆå¹³å‡å¤šä¸ªæ¨¡å‹çš„ Softmax æ¦‚ç‡ï¼Œè¿”å› [N, C]
    æ³¨æ„ï¼šæ­¤å‡½æ•°éœ€è¦ä½¿ç”¨YOLOåˆ†ç±»æ¨¡å‹ï¼Œä¸æ˜¯æ£€æµ‹æ¨¡å‹
    """
    pred_accum = None

    # ä¸ºæ¯ä¸ªæ¨¡å‹æ·»åŠ è¿›åº¦æ¡
    for model_idx, model in enumerate(models):
        probs_list = []

        # è®¡ç®—æ€»æ‰¹æ¬¡æ•°
        total_batches = (len(paths) + batch_size - 1) // batch_size

        # æ·»åŠ æ‰¹æ¬¡å¤„ç†è¿›åº¦æ¡
        batch_pbar = tqdm(
            range(0, len(paths), batch_size),
            desc=f"ğŸ”® Fold {fold_id} - æ¨¡å‹ {model_idx + 1}/{len(models)} æ¨ç†",
            total=total_batches,
            leave=False
        )

        for i in batch_pbar:
            batch = [str(p) for p in paths[i: i + batch_size]]
            results = model.predict(batch, conf=conf, verbose=False, device=0)

            for r in results:
                # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†ç±»æ¨¡å‹ç»“æœ
                if hasattr(r, 'probs') and r.probs is not None:
                    # åˆ†ç±»æ¨¡å‹
                    p = r.probs.data.cpu().numpy() if hasattr(r.probs, "data") else r.probs.cpu().numpy()
                    probs_list.append(p)
                elif hasattr(r, 'boxes') and r.boxes is not None:
                    # æ£€æµ‹æ¨¡å‹ - éœ€è¦è½¬æ¢ä¸ºåˆ†ç±»æ¦‚ç‡
                    if model_idx == 0 and i == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡è­¦å‘Š
                        tqdm.write("âš ï¸ æ£€æµ‹åˆ°ä½¿ç”¨çš„æ˜¯æ£€æµ‹æ¨¡å‹ï¼Œå°è¯•è½¬æ¢ä¸ºåˆ†ç±»æ¦‚ç‡...")

                    if len(r.boxes.cls) > 0:
                        # å–ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹æ¡†çš„ç±»åˆ«
                        max_conf_idx = r.boxes.conf.argmax()
                        cls_id = int(r.boxes.cls[max_conf_idx])
                        conf_score = float(r.boxes.conf[max_conf_idx])

                        # åˆ›å»ºone-hotæ¦‚ç‡å‘é‡
                        n_classes = len(model.names)
                        probs = np.zeros(n_classes)
                        probs[cls_id] = conf_score
                        # å°†å‰©ä½™æ¦‚ç‡å¹³å‡åˆ†é…ç»™å…¶ä»–ç±»åˆ«
                        remaining_prob = 1.0 - conf_score
                        other_prob = remaining_prob / (n_classes - 1)
                        for j in range(n_classes):
                            if j != cls_id:
                                probs[j] = other_prob
                        probs_list.append(probs)
                    else:
                        # æ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¯¹è±¡ï¼Œåˆ›å»ºå‡åŒ€åˆ†å¸ƒ
                        n_classes = len(model.names)
                        probs = np.ones(n_classes) / n_classes
                        probs_list.append(probs)
                else:
                    raise ValueError(f"âŒ æ— æ³•ä»æ¨¡å‹ç»“æœä¸­æå–æ¦‚ç‡ä¿¡æ¯ã€‚è¯·ç¡®ä¿ä½¿ç”¨çš„æ˜¯YOLOåˆ†ç±»æ¨¡å‹ã€‚")

            # æ›´æ–°è¿›åº¦æ¡åç¼€ä¿¡æ¯
            batch_pbar.set_postfix({
                'processed': f"{min(i + batch_size, len(paths))}/{len(paths)}"
            })

        probs_arr = np.vstack(probs_list)
        pred_accum = probs_arr if pred_accum is None else pred_accum + probs_arr

    return pred_accum / len(models)

# è¯„ä¼°æ‰€éœ€
from sklearn.metrics import (
    accuracy_score,
    f1_score,
    cohen_kappa_score,
    confusion_matrix,
    classification_report,
    roc_auc_score,
)
import matplotlib.pyplot as plt

# è¯´æ˜ï¼šæœŸæœ›åœ¨è°ƒç”¨æ¨¡å—ä¸­å·²å®šä¹‰å…¨å±€ CONFIG
# ä¾èµ–å¤–éƒ¨å‡½æ•° _batch_predictï¼ˆä¸åŸè„šæœ¬ä¿æŒä¸€è‡´ï¼‰

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. è®­ç»ƒè¾…åŠ©å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def train_kfold_models(
    img_paths: List[Path],
    labels: List[int],
    label_map: Dict[int, str],
    n_folds: int = CONFIG["KFOLD"],
    params: dict = CONFIG["TRAIN_PARAMS"],
) -> List[Path]:
    """ä½¿ç”¨ **StratifiedKFold** è®­ç»ƒ ``n_folds`` ä¸ª YOLO åˆ†ç±»æ¨¡å‹ã€‚

    ç¬¬ ``i`` æŠ˜æ¨¡å‹ä¸ä¼šçœ‹åˆ°ç¬¬ ``i`` æŠ˜çš„éªŒè¯æ ·æœ¬ï¼Œå› æ­¤å…¶ ``best.pt``
    éšåå¯ç”¨äºç”Ÿæˆ Outâ€‘ofâ€‘Fold (OOF) é¢„æµ‹ã€‚

    è¿”å›æŒ‰æŠ˜åºï¼ˆ0 å¼€å§‹ï¼‰çš„æƒé‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)
    df = pd.DataFrame({"path": img_paths, "label": labels})

    base_ckpt = "yolov8n-cls.pt"  # é¢„è®­ç»ƒæƒé‡ï¼Œå¯æŒ‰éœ€æ±‚æ›¿æ¢
    weight_paths: List[Path] = []

    for fold, (tr_idx, val_idx) in enumerate(skf.split(img_paths, labels)):
        fold_dir = Path("runs/cls/kfold_train") / f"fold{fold}"
        fold_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜è®­ç»ƒ / éªŒè¯æ–‡ä»¶åˆ—è¡¨ï¼›ä½¿ç”¨ ``iloc`` å¹¶è½¬ä¸º ``str`` é¿å… dtype é—®é¢˜
        (fold_dir / "train.txt").write_text("\n".join(df.iloc[tr_idx]["path"].astype(str)))
        (fold_dir / "val.txt").write_text("\n".join(df.iloc[val_idx]["path"].astype(str)))

        # YOLO éœ€è¦ç±»åˆ«åç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰
        names = [label_map[i] for i in sorted(label_map.keys())]
        data_yaml = {
            "train": str((fold_dir / "train.txt").resolve()),
            "val":   str((fold_dir / "val.txt").resolve()),
            "names": names,
        }
        (fold_dir / "data.yaml").write_text(yaml.safe_dump(data_yaml, sort_keys=False))

        best_ckpt = fold_dir / "weights" / "best.pt"
        if not best_ckpt.exists():  # è‹¥å·²è®­ç»ƒåˆ™è·³è¿‡
            model = YOLO(base_ckpt)
            model.train(
                data=str(fold_dir / "data.yaml"),
                epochs=params["epochs"],
                imgsz=params["imgsz"],
                batch=params["batch"],
                patience=params["patience"],
                project=str(fold_dir),
                name="",  # ç•™ç©º â†’ æ–‡ä»¶å¤¹åå·²å« foldX
                exist_ok=True,
                device=params["device"],
            )
        weight_paths.append(best_ckpt)

    return weight_paths
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. æ¨ç†è¾…åŠ©å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def kfold_predict(
    img_paths: List[Path],
    labels: List[int],
    weight_paths: List[Path],
    n_folds: int,
    batch_size: int,
    conf_thresh: float,
    use_cache: bool = CONFIG.get("USE_CACHE", True),
    dataset_name: str = CONFIG["DATA_DIR"].name,
) -> Tuple[np.ndarray, np.ndarray]:
    """ä½¿ç”¨é¢„è®­ç»ƒæŠ˜æ¨¡å‹ç”Ÿæˆ Outâ€‘ofâ€‘Fold æ¦‚ç‡ã€‚

    æ¯ä¸ªéªŒè¯æŠ˜ä½¿ç”¨ *é™¤æœ¬æŠ˜å¤–* çš„ ``n_folds-1`` ä¸ªæ¨¡å‹ç»„æˆé›†æˆè¿›è¡Œé¢„æµ‹ï¼Œ
    ä»¥é¿å…ä¿¡æ¯æ³„æ¼ã€‚
    """
    # ------------------------- ç¼“å­˜å¿«é€Ÿè·¯å¾„ -------------------------
    model_names = "_".join([w.parent.parent.parent.name for w in weight_paths])
    cache_dir = CONFIG["CACHE_DIR"]
    cache_dir.mkdir(parents=True, exist_ok=True)
    cache_path = cache_dir / f"{n_folds}_{dataset_name}_{model_names}.npz"

    if use_cache and cache_path.exists():
        data = np.load(cache_path)
        return data["y_true"], data["y_pred"]

    # ------------------------ è½½å…¥æ‰€æœ‰æƒé‡ -------------------------
    models: List[YOLO] = []
    for w in weight_paths:
        if not w.exists():
            raise FileNotFoundError(f"æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶: {w}")
        models.append(YOLO(str(w)))

    n_classes = len(models[0].names)
    if not all(len(m.names) == n_classes for m in models[1:]):
        raise ValueError("æ‰€æœ‰æŠ˜æ¨¡å‹å¿…é¡»æ‹¥æœ‰ç›¸åŒçš„ç±»åˆ«æ•°é‡ã€‚")

    y_true = np.array(labels, dtype=int)
    y_pred = np.zeros((len(img_paths), n_classes), dtype=float)

    # ---------------------- é‡å¤è®­ç»ƒæ—¶çš„æŠ˜åˆ’åˆ† ----------------------
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)
    fold_iter = tqdm(
        enumerate(skf.split(img_paths, labels)),
        total=n_folds,
        desc="Kâ€‘Fold æ¨ç†",
    )

    for fold, (_, val_idx) in fold_iter:
        val_paths = [img_paths[i] for i in val_idx]
        start = time.time()

        # æ’é™¤ä¸å½“å‰éªŒè¯æŠ˜åŒæºçš„æ¨¡å‹
        ensemble = [m for i, m in enumerate(models) if i != fold]
        y_pred[val_idx] = _batch_predict(
            ensemble,
            val_paths,
            batch_size,
            conf_thresh,
            fold_id=fold,
        )

        fold_iter.set_postfix(samples=len(val_idx), t=f"{time.time()-start:.1f}s")

    np.savez(cache_path, y_true=y_true, y_pred=y_pred)
    return y_true, y_pred


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. è¯„ä¼°è¾…åŠ©å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def evaluate_oof(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    label_map: Dict[int, str],
    save_dir: Optional[Path] = None,
    plot: bool = True,
) -> Dict[str, float]:
    """è¯„ä¼° OOF é¢„æµ‹ç»“æœå¹¶å¯è§†åŒ–ã€‚

    å‚æ•°
    -----
    y_true : np.ndarray
        çœŸå®æ ‡ç­¾ï¼Œä¸€ç»´æ•´æ•°æ•°ç»„ã€‚
    y_pred : np.ndarray
        é¢„æµ‹æ¦‚ç‡ï¼Œå½¢çŠ¶ä¸º ``[N, C]``ã€‚
    label_map : Dict[int, str]
        ``{label_id: label_name}`` æ˜ å°„ï¼Œç”¨äºæ··æ·†çŸ©é˜µåæ ‡ã€‚
    save_dir : Path | None
        å›¾è¡¨åŠæŠ¥å‘Šä¿å­˜ç›®å½•ï¼Œé»˜è®¤ä¸º ``runs/cls/metrics``ã€‚
    plot : bool
        æ˜¯å¦ç»˜åˆ¶å¹¶ä¿å­˜å›¾è¡¨ï¼ˆæ··æ·†çŸ©é˜µï¼‰ã€‚

    è¿”å›
    -----
    Dict[str, float]
        å…³é”®æŒ‡æ ‡å­—å…¸ï¼šaccuracyã€macro_f1ã€weighted_f1ã€kappaã€‚
    """
    if save_dir is None:
        save_dir = Path("runs/cls/metrics")
    save_dir.mkdir(parents=True, exist_ok=True)

    # å°†æ¦‚ç‡è½¬æ¢ä¸ºç±»åˆ«
    y_hat = y_pred.argmax(axis=1)

    acc = accuracy_score(y_true, y_hat)
    macro_f1 = f1_score(y_true, y_hat, average="macro", zero_division=0)
    weighted_f1 = f1_score(y_true, y_hat, average="weighted", zero_division=0)
    kappa = cohen_kappa_score(y_true, y_hat)

    # åˆ†ç±»æŠ¥å‘Šä¿å­˜ä¸º txtï¼Œæ–¹ä¾¿å¯¹é½æ£€æµ‹
    report = classification_report(
        y_true,
        y_hat,
        target_names=[label_map[i] for i in sorted(label_map.keys())],
        digits=4,
    )
    (save_dir / "classification_report.txt").write_text(report)

    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_true, y_hat, labels=list(label_map.keys()))

    if plot:
        _plot_confusion_matrix(
            cm,
            class_names=[label_map[i] for i in sorted(label_map.keys())],
            title=f"Confusion Matrix | Acc={acc:.3f}",
            save_path=save_dir / "confusion_matrix.png",
        )

    # å¤šç±»åˆ« ROCâ€‘AUCï¼šä½¿ç”¨ macroâ€‘averageï¼ˆOvRï¼‰
    try:
        roc_auc = roc_auc_score(y_true, y_pred, multi_class="ovr", average="macro")
    except ValueError:
        roc_auc = float("nan")  # è‹¥æ¦‚ç‡å…¨é›¶ç­‰æƒ…å†µæ— æ³•è®¡ç®—

    metrics = {
        "accuracy": acc,
        "macro_f1": macro_f1,
        "weighted_f1": weighted_f1,
        "kappa": kappa,
        "roc_auc_macro": roc_auc,
    }

    # ä¿å­˜æŒ‡æ ‡åˆ° csvï¼ˆè¿½åŠ  / æ›´æ–°ï¼‰
    metrics_df = pd.DataFrame([metrics])
    csv_path = save_dir / "metrics.csv"
    if csv_path.exists():
        metrics_df.to_csv(csv_path, mode="a", header=False, index=False)
    else:
        metrics_df.to_csv(csv_path, index=False)

    return metrics


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. ç§æœ‰å·¥å…·å‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _plot_confusion_matrix(
    cm: np.ndarray,
    class_names: List[str],
    title: str,
    save_path: Path,
    figsize: Tuple[int, int] = (8, 6),
) -> None:
    """ç»˜åˆ¶å¹¶ä¿å­˜æ··æ·†çŸ©é˜µã€‚"""
    fig, ax = plt.subplots(figsize=figsize)
    im = ax.imshow(cm, interpolation="nearest")
    ax.figure.colorbar(im, ax=ax)
    ax.set(
        xticks=np.arange(len(class_names)),
        yticks=np.arange(len(class_names)),
        xticklabels=class_names,
        yticklabels=class_names,
        title=title,
        ylabel="True label",
        xlabel="Predicted label",
    )

    # åœ¨æ¯ä¸ªå•å…ƒæ ¼ä¸Šå†™æ•°å­—
    thresh = cm.max() / 2.0
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(
                j,
                i,
                format(cm[i, j], "d"),
                ha="center",
                va="center",
                color="white" if cm[i, j] > thresh else "black",
                fontsize=9,
            )

    fig.tight_layout()
    fig.savefig(save_path, dpi=300)
    plt.close(fig)



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ†• å¼‚å¸¸æ£€æµ‹ç®—æ³•
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_enhanced_cleanlab(
        y_true: np.ndarray,
        pred_probs: np.ndarray,
) -> Tuple[np.ndarray, np.ndarray]:
    print("ğŸ§¹ è¿è¡Œ CleanLab...")

    cl = CleanLearning(
        DummyClassifier(strategy="prior"),
        seed=42,
        cv_n_folds=1
    )

    issues = cl.find_label_issues(
        labels=y_true,
        pred_probs=pred_probs,
    )

    # è·å–å¯ç–‘æ ·æœ¬ç´¢å¼•å’Œåˆ†æ•°
    # ä½¿ç”¨ CleanLab è¿”å›çš„ sample_index åˆ—, ä»…ä¿ç•™è¢«åˆ¤å®šä¸ºé—®é¢˜æ ‡ç­¾çš„æ ·æœ¬
    suspect_indices = issues.loc[issues["is_label_issue"], "sample_index"].to_numpy()
    # ä½ å¯ä»¥æ ¹æ®å®é™… DataFrame åˆ—åé€‰æ‹©åˆ†æ•°å­—æ®µ
    quality_scores = issues["label_quality"].to_numpy() if "label_quality" in issues.columns else np.ones(len(y_true))

    print(f"ğŸ” CleanLabæ£€æµ‹åˆ° {len(suspect_indices)} ä¸ªå¯ç–‘æ ·æœ¬")
    return suspect_indices, quality_scores


def run_kmeans_detection(
        y_true: np.ndarray,
        pred_probs: np.ndarray,
        config: dict = CONFIG["KMEANS_CONFIG"]
) -> Tuple[np.ndarray, np.ndarray]:
    """åŸºäºK-Meansçš„ç±»å†…å¼‚å¸¸æ£€æµ‹"""
    print("ğŸ¯ è¿è¡Œ K-Means ç±»å†…å¼‚å¸¸æ£€æµ‹...")

    suspect_indices = []
    anomaly_scores = np.ones(len(y_true))  # é»˜è®¤åˆ†æ•°ä¸º1(æ­£å¸¸)

    unique_labels = np.unique(y_true)

    for label in tqdm(unique_labels, desc="K-Meansç±»å†…æ£€æµ‹"):
        # è·å–å½“å‰ç±»åˆ«çš„æ ·æœ¬
        class_mask = y_true == label
        class_indices = np.where(class_mask)[0]
        class_probs = pred_probs[class_mask]

        if len(class_indices) < config["min_clusters"]:
            continue

        # åŠ¨æ€å†³å®šèšç±»æ•°
        n_samples = len(class_indices)
        n_clusters = max(
            config["min_clusters"],
            min(config["max_clusters"], int(n_samples * config["n_clusters_ratio"]))
        )

        # K-Meansèšç±»
        kmeans = KMeans(
            n_clusters=n_clusters,
            random_state=config["random_state"],
            n_init=10
        )
        cluster_labels = kmeans.fit_predict(class_probs)

        # è®¡ç®—æ¯ä¸ªæ ·æœ¬åˆ°å…¶èšç±»ä¸­å¿ƒçš„è·ç¦»
        distances = np.min(kmeans.transform(class_probs), axis=1)

        # æ ‡è®°è·ç¦»æœ€å¤§çš„æ ·æœ¬ä¸ºå¼‚å¸¸
        contamination_count = max(1, int(len(class_indices) * config["contamination"]))
        anomaly_threshold = np.percentile(distances, (1 - config["contamination"]) * 100)

        class_anomalies = class_indices[distances > anomaly_threshold]
        suspect_indices.extend(class_anomalies)

        # è®°å½•å¼‚å¸¸åˆ†æ•° (è·ç¦»è¶Šå¤§åˆ†æ•°è¶Šä½)
        max_dist = distances.max()
        for i, dist in enumerate(distances):
            anomaly_scores[class_indices[i]] = 1 - (dist / max_dist) if max_dist > 0 else 1.0

    suspect_indices = np.array(suspect_indices)
    print(f"ğŸ¯ K-Meansæ£€æµ‹åˆ° {len(suspect_indices)} ä¸ªç±»å†…å¼‚å¸¸æ ·æœ¬")

    return suspect_indices, anomaly_scores


def run_isolation_forest(
        y_true: np.ndarray,
        pred_probs: np.ndarray,
        config: dict = CONFIG["ISOLATION_CONFIG"]
) -> Tuple[np.ndarray, np.ndarray]:
    """Isolation Forestå…¨å±€å¼‚å¸¸æ£€æµ‹"""
    print("ğŸŒ² è¿è¡Œ Isolation Forest å…¨å±€å¼‚å¸¸æ£€æµ‹...")

    # ç‰¹å¾å·¥ç¨‹ï¼šç»“åˆé¢„æµ‹æ¦‚ç‡å’Œæ ‡ç­¾ä¿¡æ¯
    features = []

    # 1. åŸå§‹é¢„æµ‹æ¦‚ç‡
    features.append(pred_probs)

    # 2. é¢„æµ‹ç½®ä¿¡åº¦ (æœ€å¤§æ¦‚ç‡)
    confidence = pred_probs.max(axis=1).reshape(-1, 1)
    features.append(confidence)

    # 3. é¢„æµ‹ç†µ (ä¸ç¡®å®šæ€§)
    entropy = -np.sum(pred_probs * np.log(pred_probs + 1e-8), axis=1).reshape(-1, 1)
    features.append(entropy)

    # 4. æ ‡ç­¾ä¸€è‡´æ€§ (çœŸå®æ ‡ç­¾çš„é¢„æµ‹æ¦‚ç‡)
    label_consistency = pred_probs[np.arange(len(y_true)), y_true].reshape(-1, 1)
    features.append(label_consistency)

    # åˆå¹¶ç‰¹å¾
    X = np.hstack(features)

    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # é™ç»´ (å¯é€‰)
    if X_scaled.shape[1] > 10:
        pca = PCA(n_components=min(10, X_scaled.shape[1]))
        X_scaled = pca.fit_transform(X_scaled)

    # Isolation Forest
    iso_forest = IsolationForest(
        contamination=config["contamination"],
        n_estimators=config["n_estimators"],
        random_state=config["random_state"],
        n_jobs=config["n_jobs"]
    )

    anomaly_labels = iso_forest.fit_predict(X_scaled)
    anomaly_scores = iso_forest.score_samples(X_scaled)

    # è½¬æ¢åˆ†æ•°åˆ° [0, 1] èŒƒå›´ (åˆ†æ•°è¶Šä½è¶Šå¼‚å¸¸)
    anomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())

    suspect_indices = np.where(anomaly_labels == -1)[0]

    print(f"ğŸŒ² Isolation Forestæ£€æµ‹åˆ° {len(suspect_indices)} ä¸ªå…¨å±€å¼‚å¸¸æ ·æœ¬")
    return suspect_indices, anomaly_scores


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ†• é›†æˆå†³ç­–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ensemble_decision(
        y_true: np.ndarray,
        cleanlab_suspects: np.ndarray,
        cleanlab_scores: np.ndarray,
        kmeans_suspects: np.ndarray,
        kmeans_scores: np.ndarray,
        isolation_suspects: np.ndarray,
        isolation_scores: np.ndarray,
        config: dict = CONFIG["ENSEMBLE_CONFIG"]
) -> pd.DataFrame:
    """é›†æˆå¤šä¸ªç®—æ³•çš„å¼‚å¸¸æ£€æµ‹ç»“æœ"""
    print("ğŸ¤ é›†æˆå¤šç®—æ³•æ£€æµ‹ç»“æœ...")

    n_samples = len(y_true)
    results = []

    # åˆ›å»ºæŠ•ç¥¨çŸ©é˜µ
    votes = np.zeros((n_samples, 3))  # [cleanlab, kmeans, isolation]
    votes[cleanlab_suspects, 0] = 1
    votes[kmeans_suspects, 1] = 1
    votes[isolation_suspects, 2] = 1

    weights = np.array([
        config["quality_score_weight"]["cleanlab"],
        config["quality_score_weight"]["kmeans"],
        config["quality_score_weight"]["isolation"]
    ])

    for i in range(n_samples):
        # æŠ•ç¥¨ç»Ÿè®¡
        vote_count = votes[i].sum()
        weighted_vote = np.dot(votes[i], weights)

        # ç»¼åˆè´¨é‡åˆ†æ•° (è¶Šä½è¶Šå¯ç–‘)
        composite_score = (
                cleanlab_scores[i] * config["quality_score_weight"]["cleanlab"] +
                kmeans_scores[i] * config["quality_score_weight"]["kmeans"] +
                isolation_scores[i] * config["quality_score_weight"]["isolation"]
        )

        # æœ€ç»ˆå†³ç­–
        is_suspect = vote_count >= config["voting_threshold"]

        results.append({
            "index": i,
            "cleanlab_suspect": i in cleanlab_suspects,
            "kmeans_suspect": i in kmeans_suspects,
            "isolation_suspect": i in isolation_suspects,
            "vote_count": int(vote_count),
            "weighted_vote": weighted_vote,
            "composite_score": composite_score,
            "is_suspect": is_suspect
        })

    df_results = pd.DataFrame(results)

    # ç»Ÿè®¡ä¿¡æ¯
    total_suspects = df_results["is_suspect"].sum()
    print(f"ğŸ¤ é›†æˆç»“æœ: {total_suspects}/{n_samples} æ ·æœ¬è¢«æ ‡è®°ä¸ºå¯ç–‘ ({total_suspects / n_samples * 100:.2f}%)")

    # å„ç®—æ³•è´¡çŒ®ç»Ÿè®¡
    print("ğŸ“Š å„ç®—æ³•æ£€æµ‹ç»Ÿè®¡:")
    print(f"   CleanLab: {len(cleanlab_suspects)} ä¸ª")
    print(f"   K-Means: {len(kmeans_suspects)} ä¸ª")
    print(f"   Isolation Forest: {len(isolation_suspects)} ä¸ª")
    print(f"   æœ€ç»ˆé›†æˆ: {total_suspects} ä¸ª")

    return df_results.sort_values("composite_score")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ”„ å¯¼å‡ºå‡½æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def export_enhanced_results(
        df_ensemble: pd.DataFrame,
        img_paths: List[Path],
        label_map: Dict[int, str],
        y_true: np.ndarray,
        output_dir: Path = CONFIG["OUTPUT_DIR"],
        suspects_dir: Path = CONFIG["SUSPECTS_DIR"],
        clean_dir: Path = CONFIG["CLEAN_DIR"],
        save_suspects: bool = CONFIG["SAVE_IMGS"],
) -> None:
    """å¯¼å‡ºç»“æœï¼šä¿å­˜CSVå’Œå¤åˆ¶å›¾ç‰‡"""
    print("ğŸ’¾ å¼€å§‹å¯¼å‡ºå¢å¼ºç‰ˆç»“æœ...")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    if save_suspects:
        suspects_dir.mkdir(parents=True, exist_ok=True)
    clean_dir.mkdir(parents=True, exist_ok=True)

    # å‡†å¤‡å®Œæ•´çš„ç»“æœDataFrame
    suspect_indices = set(df_ensemble[df_ensemble["is_suspect"]]["index"].tolist())

    print("ğŸ“ å‡†å¤‡å¢å¼ºç‰ˆç»“æœæ•°æ®...")
    results = []
    for idx, img_path in enumerate(tqdm(img_paths, desc="å¤„ç†ç»“æœæ•°æ®")):
        row_data = df_ensemble[df_ensemble["index"] == idx].iloc[0]
        is_suspect = row_data["is_suspect"]

        results.append({
            "index": idx,
            "image_path": str(img_path),
            "true_label": y_true[idx],
            "true_label_name": label_map[y_true[idx]],
            "is_suspect": is_suspect,
            "cleanlab_suspect": row_data["cleanlab_suspect"],
            "kmeans_suspect": row_data["kmeans_suspect"],
            "isolation_suspect": row_data["isolation_suspect"],
            "vote_count": row_data["vote_count"],
            "weighted_vote": row_data["weighted_vote"],
            "composite_score": row_data["composite_score"]
        })

    df_results = pd.DataFrame(results)

    # ä¿å­˜CSV
    csv_path = output_dir / "enhanced_label_issues.csv"
    df_results.to_csv(csv_path, index=False)
    print(f"ğŸ’¾ å¢å¼ºç‰ˆç»“æœå·²ä¿å­˜åˆ°: {csv_path}")

    # å¤åˆ¶å¯ç–‘å›¾ç‰‡
    if save_suspects and len(suspect_indices) > 0:
        print("ğŸ“‹ å¤åˆ¶å¯ç–‘å›¾ç‰‡...")
        for idx in tqdm(suspect_indices, desc="å¤åˆ¶å¯ç–‘å›¾ç‰‡"):
            src_path = img_paths[idx]
            true_label_name = label_map[y_true[idx]]

            # æ·»åŠ ç®—æ³•æ ‡è¯†
            row_data = df_ensemble[df_ensemble["index"] == idx].iloc[0]
            algo_flags = []
            if row_data["cleanlab_suspect"]: algo_flags.append("CL")
            if row_data["kmeans_suspect"]: algo_flags.append("KM")
            if row_data["isolation_suspect"]: algo_flags.append("IF")
            algo_str = "-".join(algo_flags)

            dst_path = suspects_dir / f"{idx}_{true_label_name}_{algo_str}_{src_path.name}"
            shutil.copy2(src_path, dst_path)
        print(f"âœ… å¯ç–‘å›¾ç‰‡å·²å¤åˆ¶åˆ°: {suspects_dir}")

    # å¤åˆ¶å¹²å‡€å›¾ç‰‡
    clean_indices = [i for i in range(len(img_paths)) if i not in suspect_indices]
    print(f"ğŸ“‹ å¤åˆ¶å¹²å‡€å›¾ç‰‡ ({len(clean_indices)} å¼ )...")

    # æŒ‰ç±»åˆ«ç»„ç»‡å¹²å‡€å›¾ç‰‡ï¼Œæ·»åŠ è¿›åº¦æ¡
    for idx in tqdm(clean_indices, desc="å¤åˆ¶å¹²å‡€å›¾ç‰‡"):
        src_path = img_paths[idx]
        true_label = y_true[idx]
        label_name = label_map[true_label]

        # åˆ›å»ºç±»åˆ«ç›®å½•
        class_dir = clean_dir / label_name
        class_dir.mkdir(parents=True, exist_ok=True)

        dst_path = class_dir / src_path.name
        shutil.copy2(src_path, dst_path)

    print(f"âœ… å¹²å‡€å›¾ç‰‡å·²å¤åˆ¶åˆ°: {clean_dir}")
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    print(f"   æ€»å›¾ç‰‡æ•°: {len(img_paths)}")
    print(f"   å¯ç–‘å›¾ç‰‡: {len(suspect_indices)} ({len(suspect_indices) / len(img_paths) * 100:.2f}%)")
    print(f"   å¹²å‡€å›¾ç‰‡: {len(clean_indices)} ({len(clean_indices) / len(img_paths) * 100:.2f}%)")

    # æŒ‰ç±»åˆ«æ˜¾ç¤ºå¯ç–‘å›¾ç‰‡åˆ†å¸ƒ
    if len(suspect_indices) > 0:
        print(f"ğŸ“Š å„ç±»åˆ«å¯ç–‘å›¾ç‰‡åˆ†å¸ƒ:")
        suspect_by_class = {}
        for idx in suspect_indices:
            true_label = y_true[idx]
            label_name = label_map[true_label]
            suspect_by_class[label_name] = suspect_by_class.get(label_name, 0) + 1

        for label_name, count in sorted(suspect_by_class.items()):
            total_in_class = sum(1 for label in y_true if label_map[label] == label_name)
            print(f"   {label_name}: {count}/{total_in_class} ({count / total_in_class * 100:.1f}%)")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ä¸»æµç¨‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    """å¢å¼ºç‰ˆä¸»æµç¨‹"""
    start_time = time.time()

    print("ğŸ¯ å¼€å§‹å¢å¼ºç‰ˆAffectNetæ ‡ç­¾æ¸…æ´—")
    print("=" * 70)

    try:
        # 1. åŠ è½½æ•°æ®
        print("\nğŸ“Š æ­¥éª¤ 1/7: åŠ è½½æ•°æ®é›†")
        img_paths, labels, label_map = load_dataset(CONFIG["DATA_DIR"])

        # 2. æ¨¡å‹æ¨ç†
        print("\nğŸš€ æ­¥éª¤ 2/7: KæŠ˜äº¤å‰éªŒè¯æ¨ç†")

        weight_paths = train_kfold_models(img_paths, labels)

        y_true, pred_probs = kfold_predict(
            img_paths, labels, weight_paths,
            CONFIG["KFOLD"], CONFIG["BATCH_SIZE"], CONFIG["CONF_THRESH"]
        )

        # 3. CleanLabæ£€æµ‹
        print("\nğŸ§¹ æ­¥éª¤ 3/7: CleanLabå¼‚å¸¸æ£€æµ‹")
        cleanlab_suspects, cleanlab_scores = run_enhanced_cleanlab(y_true, pred_probs)

        # 4. K-Meansæ£€æµ‹
        print("\nğŸ¯ æ­¥éª¤ 4/7: K-Meansç±»å†…å¼‚å¸¸æ£€æµ‹")
        kmeans_suspects, kmeans_scores = run_kmeans_detection(y_true, pred_probs)

        # 5. Isolation Forestæ£€æµ‹
        print("\nğŸŒ² æ­¥éª¤ 5/7: Isolation Forestå…¨å±€æ£€æµ‹")
        isolation_suspects, isolation_scores = run_isolation_forest(y_true, pred_probs)

        # 6. é›†æˆå†³ç­–
        print("\nğŸ¤ æ­¥éª¤ 6/7: é›†æˆå¤šç®—æ³•ç»“æœ")
        df_ensemble = ensemble_decision(
            y_true, cleanlab_suspects, cleanlab_scores,
            kmeans_suspects, kmeans_scores,
            isolation_suspects, isolation_scores
        )

        # 7. å¯¼å‡ºç»“æœ
        print("\nğŸ’¾ æ­¥éª¤ 7/7: å¯¼å‡ºå¢å¼ºç‰ˆç»“æœ")
        output_dir = CONFIG["OUTPUT_DIR"]
        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜è¯¦ç»†ç»“æœ
        csv_path = output_dir / "enhanced_label_issues.csv"

        # æ·»åŠ å›¾ç‰‡è·¯å¾„å’Œæ ‡ç­¾ä¿¡æ¯
        df_final = df_ensemble.copy()
        df_final["image_path"] = [str(p) for p in img_paths]
        df_final["true_label"] = y_true
        df_final["true_label_name"] = [label_map[l] for l in y_true]
        df_final["pred_label"] = pred_probs.argmax(axis=1)
        df_final["pred_label_name"] = [label_map[l] for l in pred_probs.argmax(axis=1)]

        df_final.to_csv(csv_path, index=False)
        print(f"ğŸ’¾ å¢å¼ºç‰ˆç»“æœå·²ä¿å­˜: {csv_path}")

        # å¤åˆ¶å¹²å‡€å›¾ç‰‡ (åŸºäºé›†æˆç»“æœ)
        clean_dir = CONFIG["CLEAN_DIR"]
        clean_dir.mkdir(parents=True, exist_ok=True)

        clean_samples = df_final[~df_final["is_suspect"]]
        print(f"ğŸ“‹ å¤åˆ¶ {len(clean_samples)} å¼ å¹²å‡€å›¾ç‰‡...")

        for _, row in tqdm(clean_samples.iterrows(), total=len(clean_samples), desc="å¤åˆ¶å¹²å‡€å›¾ç‰‡"):
            src_path = Path(row["image_path"])
            label_name = row["true_label_name"]
            class_dir = clean_dir / label_name
            class_dir.mkdir(exist_ok=True)
            dst_path = class_dir / src_path.name
            shutil.copy2(src_path, dst_path)

        total_time = time.time() - start_time
        print(f"\nğŸ‰ å¢å¼ºç‰ˆæ¸…æ´—å®Œæˆï¼æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print("=" * 70)

    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()